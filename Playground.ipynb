{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri May  4 21:21:56 2018\n",
    "\n",
    "@author: shen1994\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import gensim\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from log import setUpLogger\n",
    "\n",
    "from data_create import create_label_data\n",
    "\n",
    "from data_preprocess import DataPreprocess\n",
    "\n",
    "from data_generate import generate_batch\n",
    "\n",
    "from bilstm_cnn_crf import bilstm_cnn_crf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from paths import TrainPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--corpus_path\", help=\"corpus path\", default=\"/home/jovyan/shared/corpus/2014/\", type=str)\n",
    "parser.add_argument(\"--batch_size\", help=\"batch size\", default=256, type=int)\n",
    "parser.add_argument(\"--epochs\", help=\"epochs\", default=3, type=int)\n",
    "parser.add_argument(\n",
    "    \"--train_dir\", help=\"train directory\", default=\"/home/jovyan/shared/\", type=str\n",
    ")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "corpus_path = args.corpus_path\n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "\n",
    "trainPath = TrainPath(args.train_dir)\n",
    "\n",
    "setUpLogger(trainPath)\n",
    "dataPreprocess = DataPreprocess(trainPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-1--->\" + u\"加载词向量模型\" + \"--->START\")\n",
    "embedding_model = gensim.models.Word2Vec.load(trainPath.model_vector_path)\n",
    "\n",
    "word_dict = dataPreprocess.create_useful_words(embedding_model)\n",
    "\n",
    "embedding_size = embedding_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/shared/corpus/2014/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-2--->\" + u\"语料格式转换,加标注生成标准文件\" + \"--->START\")\n",
    "\n",
    "def path_flatten(path, includes=['.txt']):\n",
    "    paths = []\n",
    "    for subpath in os.listdir(path):\n",
    "        for include in includes:\n",
    "            relpath = os.path.join(path, subpath)\n",
    "            if os.path.isfile(relpath) and include == 'any':\n",
    "                paths.append(relpath)\n",
    "            elif os.path.isfile(relpath) and relpath.endswith(include):\n",
    "                paths.append(relpath)\n",
    "            elif os.path.isdir(relpath):\n",
    "                paths += path_flatten(relpath, includes=includes)\n",
    "    return paths\n",
    "flated_paths = path_flatten(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flated_paths[0]\n",
    "create_label_data(trainPath, word_dict, flated_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-3--->\" + u\"按标点符号或是空格存储文件\" + \"--->START\")\n",
    "\n",
    "documents_length = dataPreprocess.create_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-4--->\" + u\"对语料中的词统计排序生成索引\" + \"--->START\")\n",
    "\n",
    "lexicon, lexicon_reverse = dataPreprocess.create_lexicon(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-5--->\" + u\"对所有的词创建词向量\" + \"--->START\")\n",
    "\n",
    "useful_word_length, embedding_weights = dataPreprocess.create_embedding(\n",
    "    embedding_model, embedding_size, lexicon_reverse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-6--->\" + u\"生成标注以及索引\" + \"--->START\")\n",
    "\n",
    "label_2_index = dataPreprocess.create_label_index()\n",
    "\n",
    "label_2_index_length = len(label_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-7--->\" + u\"将语料中每一句和label进行索引编码\" + \"--->START\")\n",
    "\n",
    "dataPreprocess.create_matrix(lexicon, label_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-8--->\" + u\"将语料中每一句和label以最大长度统一长度,不足补零\" + \"--->START\")\n",
    "\n",
    "#max_len = dataPreprocess.maxlen_2d_list()\n",
    "max_len=306\n",
    "\n",
    "dataPreprocess.padding_sentences(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-9--->\" + u\"模型创建\" + \"--->START\")\n",
    "\n",
    "model = bilstm_cnn_crf(\n",
    "    max_len,\n",
    "    useful_word_length + 2,\n",
    "    label_2_index_length,\n",
    "    embedding_size,\n",
    "    embedding_weights,\n",
    ")\n",
    "logger.info(\"setp-9.1--->\" + \"加载模型\" + \"--->START\")\n",
    "model.load_weights(trainPath.checkpoints_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-10--->\" + u\"模型训练\" + \"--->START\")\n",
    "\n",
    "if batch_size > documents_length:\n",
    "\n",
    "    logger.info(\"ERROR--->\" + u\"语料数据量过少，请再添加一些\")\n",
    "\n",
    "    return None\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    trainPath.checkpoints_path,\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "_ = model.fit_generator(\n",
    "    generator=generate_batch(\n",
    "        batch_size=batch_size, label_class=label_2_index_length\n",
    "    ),\n",
    "    steps_per_epoch=int(documents_length / batch_size),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    workers=1,\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger.info(\"step-11--->\" + u\"模型和字典保存\" + \"--->START\")\n",
    "\n",
    "    model.save_weights(trainPath.weights_path)\n",
    "\n",
    "    index_2_label = dataPreprocess.create_index_label()\n",
    "\n",
    "    pickle.dump([lexicon, index_2_label], open(trainPath.lexicon_path, \"wb\"))\n",
    "\n",
    "    pickle.dump(\n",
    "        [max_len, embedding_size, useful_word_length + 2, label_2_index_length],\n",
    "        open(trainPath.model_params_path, \"wb\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger.info(\"step-12--->\" + u\"打印恢复模型的重要参数\" + \"--->START\")\n",
    "\n",
    "    logger.info(\"sequence_max_length: \" + str(max_len))\n",
    "\n",
    "    logger.info(\"embedding size: \" + str(embedding_size))\n",
    "\n",
    "    logger.info(\"useful_word_length: \" + str(useful_word_length + 2))\n",
    "\n",
    "    logger.info(\"label_2_index_length: \" + str(label_2_index_length))\n",
    "\n",
    "    logger.info(u\"训练完成\" + \"--->OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
