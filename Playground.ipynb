{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri May  4 21:21:56 2018\n",
    "\n",
    "@author: shen1994\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import gensim\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from log import setUpLogger\n",
    "\n",
    "from data_create import create_label_data\n",
    "\n",
    "from data_preprocess import DataPreprocess\n",
    "\n",
    "from data_generate import generate_batch\n",
    "\n",
    "from bilstm_cnn_crf import bilstm_cnn_crf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from paths import TrainPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--corpus_path\", help=\"corpus path\", default=\"/home/jovyan/shared/corpus/2014/\", type=str)\n",
    "parser.add_argument(\"--batch_size\", help=\"batch size\", default=256, type=int)\n",
    "parser.add_argument(\"--epochs\", help=\"epochs\", default=3, type=int)\n",
    "parser.add_argument(\n",
    "    \"--train_dir\", help=\"train directory\", default=\"/home/jovyan/shared/\", type=str\n",
    ")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "corpus_path = args.corpus_path\n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "\n",
    "trainPath = TrainPath(args.train_dir)\n",
    "\n",
    "setUpLogger(trainPath)\n",
    "dataPreprocess = DataPreprocess(trainPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-1--->\" + u\"加载词向量模型\" + \"--->START\")\n",
    "embedding_model = gensim.models.Word2Vec.load(trainPath.model_vector_path)\n",
    "\n",
    "word_dict = dataPreprocess.create_useful_words(embedding_model)\n",
    "\n",
    "embedding_size = embedding_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/shared/corpus/2014/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-2--->\" + u\"语料格式转换,加标注生成标准文件\" + \"--->START\")\n",
    "\n",
    "def path_flatten(path, includes=['.txt']):\n",
    "    paths = []\n",
    "    for subpath in os.listdir(path):\n",
    "        for include in includes:\n",
    "            relpath = os.path.join(path, subpath)\n",
    "            if os.path.isfile(relpath) and include == 'any':\n",
    "                paths.append(relpath)\n",
    "            elif os.path.isfile(relpath) and relpath.endswith(include):\n",
    "                paths.append(relpath)\n",
    "            elif os.path.isdir(relpath):\n",
    "                paths += path_flatten(relpath, includes=includes)\n",
    "    return paths\n",
    "flated_paths = path_flatten(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/shared/corpus/2014/0101/c1002-23995935.txt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flated_paths[0]\n",
    "# create_label_data(trainPath, word_dict, flated_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-3--->\" + u\"按标点符号或是空格存储文件\" + \"--->START\")\n",
    "\n",
    "documents_length = dataPreprocess.create_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2531574"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-4--->\" + u\"对语料中的词统计排序生成索引\" + \"--->START\")\n",
    "\n",
    "lexicon, lexicon_reverse = dataPreprocess.create_lexicon(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-5--->\" + u\"对所有的词创建词向量\" + \"--->START\")\n",
    "\n",
    "useful_word_length, embedding_weights = dataPreprocess.create_embedding(\n",
    "    embedding_model, embedding_size, lexicon_reverse\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-6--->\" + u\"生成标注以及索引\" + \"--->START\")\n",
    "\n",
    "label_2_index = dataPreprocess.create_label_index()\n",
    "\n",
    "label_2_index_length = len(label_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-7--->\" + u\"将语料中每一句和label进行索引编码\" + \"--->START\")\n",
    "\n",
    "dataPreprocess.create_matrix(lexicon, label_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"step-8--->\" + u\"将语料中每一句和label以最大长度统一长度,不足补零\" + \"--->START\")\n",
    "\n",
    "#max_len = dataPreprocess.maxlen_2d_list()\n",
    "max_len=306\n",
    "\n",
    "# dataPreprocess.padding_sentences(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri May  4 10:18:27 2018\n",
    "\n",
    "@author: shen1994\n",
    "\"\"\"\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import ZeroPadding1D\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def bilstm_cnn_crf(\n",
    "    maxlen,\n",
    "    useful_word_len,\n",
    "    class_label_count,\n",
    "    embedding_size,\n",
    "    embedding_weights=None,\n",
    "    is_train=True,\n",
    "):\n",
    "    word_input = Input(shape=(maxlen,), dtype=\"int32\", name=\"word_input\")\n",
    "\n",
    "    if is_train:\n",
    "        word_emb = Embedding(\n",
    "            useful_word_len,\n",
    "            output_dim=embedding_size,\n",
    "            input_length=maxlen,\n",
    "            weights=[embedding_weights],\n",
    "            name=\"word_emb\",\n",
    "        )(word_input)\n",
    "    else:\n",
    "        word_emb = Embedding(\n",
    "            useful_word_len,\n",
    "            output_dim=embedding_size,\n",
    "            input_length=maxlen,\n",
    "            name=\"word_emb\",\n",
    "        )(word_input)\n",
    "\n",
    "    # bilstm\n",
    "    bilstm = Bidirectional(LSTM(64, return_sequences=True))(word_emb)\n",
    "    bilstm_drop = Dropout(0.1)(bilstm)\n",
    "    bilstm_dense = TimeDistributed(Dense(embedding_size))(bilstm_drop)\n",
    "\n",
    "    # cnn\n",
    "    half_window_size = 2\n",
    "    filter_kernel_number = 64\n",
    "    padding_layer = ZeroPadding1D(padding=half_window_size)(word_emb)\n",
    "    conv = Conv1D(\n",
    "        nb_filter=filter_kernel_number,\n",
    "        filter_length=2 * half_window_size + 1,\n",
    "        padding=\"valid\",\n",
    "    )(padding_layer)\n",
    "    conv_drop = Dropout(0.1)(conv)\n",
    "    conv_dense = TimeDistributed(Dense(filter_kernel_number))(conv_drop)\n",
    "\n",
    "    # merge\n",
    "    rnn_cnn_merge = Concatenate(axis=2)([bilstm_dense, conv_dense])\n",
    "#     rnn_cnn_merge = Concatenate([bilstm_dense, conv_dense], axis=2)\n",
    "    dense = TimeDistributed(Dense(class_label_count))(rnn_cnn_merge)\n",
    "\n",
    "    # crf\n",
    "    crf = CRF(class_label_count, sparse_target=False)\n",
    "    crf_output = crf(dense)\n",
    "\n",
    "    # mdoel\n",
    "    model = Model(input=[word_input], output=crf_output)\n",
    "    model.compile(loss=crf.loss_function, optimizer=\"adam\", metrics=[crf.accuracy])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:62: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(padding=\"valid\", filters=64, kernel_size=5)`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"cr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_input (InputLayer)         (None, 306)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_emb (Embedding)            (None, 306, 128)     833280      word_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d_6 (ZeroPadding1D (None, 310, 128)     0           word_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 306, 128)     98816       word_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 306, 64)      41024       zero_padding1d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 306, 128)     0           bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 306, 64)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 306, 128)     16512       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 306, 64)      4160        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 306, 192)     0           time_distributed_14[0][0]        \n",
      "                                                                 time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 306, 6)       1158        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "crf_3 (CRF)                     (None, 306, 6)       90          time_distributed_16[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 995,040\n",
      "Trainable params: 995,040\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"step-9--->\" + u\"模型创建\" + \"--->START\")\n",
    "\n",
    "model = bilstm_cnn_crf(\n",
    "    max_len,\n",
    "    useful_word_length + 2,\n",
    "    label_2_index_length,\n",
    "    embedding_size,\n",
    "    embedding_weights,\n",
    ")\n",
    "logger.info(\"setp-9.1--->\" + \"加载模型\" + \"--->START\")\n",
    "# model.load_weights(trainPath.checkpoints_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May  7 13:55:07 2018\n",
    "\n",
    "@author: shen1994\n",
    "\"\"\"\n",
    "\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from fake_keras import to_categorical\n",
    "\n",
    "\n",
    "def generate_batch(trainPath, batch_size=None, label_class=None):\n",
    "\n",
    "    batch_count = 0\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        data_index_padding = codecs.open(trainPath.data_index_padding_path, \"r\", \"utf-8\")\n",
    "        label_index_padding = codecs.open(trainPath.label_index_padding_path, \"r\", \"utf-8\")\n",
    "\n",
    "        data_line = data_index_padding.readline()\n",
    "        label_line = label_index_padding.readline()\n",
    "\n",
    "        while data_line and label_line:\n",
    "\n",
    "            data_str_list = data_line.strip().split()\n",
    "            label_str_list = label_line.strip().split()\n",
    "\n",
    "            data_list = []\n",
    "            label_list = []\n",
    "            for data in data_str_list:\n",
    "                data_list.append(int(data))\n",
    "\n",
    "            for label in label_str_list:\n",
    "                label_list.append(int(label))\n",
    "\n",
    "            X.append(data_list)\n",
    "            Y.append(label_list)\n",
    "\n",
    "            batch_count += 1\n",
    "\n",
    "            if batch_count == batch_size:\n",
    "\n",
    "                batch_count = 0\n",
    "\n",
    "                X_ARRAY = np.array(X)\n",
    "                Y_ARRAY = np.array(Y)\n",
    "\n",
    "                Y_CLASS = to_categorical(Y_ARRAY, label_class).reshape(\n",
    "                    (len(Y_ARRAY), len(Y_ARRAY[0]), -1)\n",
    "                )\n",
    "\n",
    "                yield (X_ARRAY, Y_CLASS)\n",
    "\n",
    "                X = []\n",
    "                Y = []\n",
    "\n",
    "            data_line = data_index_padding.readline()\n",
    "            label_line = label_index_padding.readline()\n",
    "\n",
    "    data_index_padding.close()\n",
    "    label_index_padding.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py:718: UserWarning: An input could not be retrieved. It could be because a worker has died.We do not have any information on the lost sample.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-db07286976be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.info(\"step-10--->\" + u\"模型训练\" + \"--->START\")\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    trainPath.checkpoints_path,\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "_ = model.fit_generator(\n",
    "    generator=generate_batch(\n",
    "        trainPath=trainPath,\n",
    "        batch_size=batch_size, label_class=label_2_index_length\n",
    "    ),\n",
    "    steps_per_epoch=int(documents_length / batch_size),\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    workers=1,\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger.info(\"step-11--->\" + u\"模型和字典保存\" + \"--->START\")\n",
    "\n",
    "    model.save_weights(trainPath.weights_path)\n",
    "\n",
    "    index_2_label = dataPreprocess.create_index_label()\n",
    "\n",
    "    pickle.dump([lexicon, index_2_label], open(trainPath.lexicon_path, \"wb\"))\n",
    "\n",
    "    pickle.dump(\n",
    "        [max_len, embedding_size, useful_word_length + 2, label_2_index_length],\n",
    "        open(trainPath.model_params_path, \"wb\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "    logger.info(\"step-12--->\" + u\"打印恢复模型的重要参数\" + \"--->START\")\n",
    "\n",
    "    logger.info(\"sequence_max_length: \" + str(max_len))\n",
    "\n",
    "    logger.info(\"embedding size: \" + str(embedding_size))\n",
    "\n",
    "    logger.info(\"useful_word_length: \" + str(useful_word_length + 2))\n",
    "\n",
    "    logger.info(\"label_2_index_length: \" + str(label_2_index_length))\n",
    "\n",
    "    logger.info(u\"训练完成\" + \"--->OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
